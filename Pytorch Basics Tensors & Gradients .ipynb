{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c135791e-ad67-496a-8b26-3213b03b1a0c",
   "metadata": {},
   "source": [
    "# Import Torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277485ba-29f1-4099-beca-7c074b816c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfcbb9-a59b-4359-9400-b1c38ba34327",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125eaf06-2a05-44aa-8149-770042fa72ac",
   "metadata": {},
   "source": [
    "In its github page it says that Pytorch 2 important features first is tensors. A tensor is a number,vector,matrix or a n-dimensional array. So Tensor is like a numpy array and Pytorch is kind of Numpy on steroids and can work on GPUs. The second thing is the auto_grad which allows us to take gradients. Actually these two are the building blocks of any neural network. Data & Gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2c0fe5-0ba8-4bde-b34a-67c83075e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create number 4 (integer) as a tensor, it can take floats etc. as well\n",
    "t1 = torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d0e0cc-3b5b-4f43-8528-d937b8a09464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2dd7c6c-4479-432b-8dce-05b92576f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ba507e-c8de-4846-82b6-0e363d312e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cacd52-6400-44df-96bc-7d377d9301a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c05cba3-b002-47da-9899-9ee5ccd7f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check torch.tensor?\n",
    "#It can take list,tuples,numpy arrays as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3167454-3bfc-470d-8d88-54b08a922492",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(np.zeros((12,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2882d00a-9b6b-49ad-ac28-5fea1d4a9f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92b3a510-8648-4746-9979-92c8531a282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057c4c2b-27e8-4add-a9a9-968806c3b400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "#A vector as in numpy and as in linear algebra. As in numpy, an vector/matric etc\n",
    "#a numpy array or a pytorch tensor needs to be in one data type\n",
    "#Thus once I give the first number as 1.0 (float) all the data converted to float \n",
    "t2 = torch.tensor([1.0,2,3,4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c29001-0e25-4500-b1d3-65efa73f59ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38c5a7a6-d681-4c98-89af-9b16453bad84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "t3 = torch.tensor([[1,2,3],\n",
    "                   [4,5,6]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9ddd71f-cb32-4625-8567-30aeb33abb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Dimensional Array\n",
    "#Think it like a cube or -dikdörtgenler prizması-\n",
    "#In space we gather around the matrices and they have like depth \n",
    "#We combine them in a new axis.\n",
    "t4 = torch.tensor([\n",
    "                    [[1,2,3],\n",
    "                     [4,5,6]], # Matrix One\n",
    "                     [[7,8,9],\n",
    "                    [10,11,12]] # Matrix Two\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1caad1a-8a01-465b-a0dd-bc23eb60b81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd2142fc-052e-47f3-ab5e-062e262b5c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Matrices with shape 2 rows 3 columns\n",
    "#Another perspective is the shape gives it from the outer most array\n",
    "#In the outer most array there are 2 elements which are also arrays \n",
    "#Inside every one of those 2 elements (arrays) we have 2 more arrays with each have 3 elements\n",
    "#Thus 3 dimensional array.\n",
    "#This is useful since it is how we defined it in the first place. \n",
    "#Shape works just like in numpy\n",
    "#3 Dimensional Array\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57adf83b-a20e-4899-b1ed-987b541e8fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "#2 rows 3 columns\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cd4ed78-2faf-4fc9-ae93-a540bfc32f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "#4 rows (If think it as column vector) or 4 columns (for a row vector)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d8ec21-ba72-4d22-a889-050b94c86815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For scalar numbers it has no shape 0 dimensional (?) I guess.\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24410047-08c8-4dc0-a877-f80af50406f1",
   "metadata": {},
   "source": [
    "# Tensor Operations and Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8415407-c1fb-4916-b14f-2f3b61b56579",
   "metadata": {},
   "source": [
    "Once we have tensors arrays or matrices as in linear algebra now we will combine them. Linear combination of the vectors and matrices really is the back bone of everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "463285ed-cc0a-4ac9-ad82-3f4c597ac976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tensors\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4.,requires_grad = True)\n",
    "b = torch.tensor(5.,requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "200e215c-a6e5-437e-8afd-57fbfc1c92b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f533480e-f26e-4818-ad14-4b3863fd08b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = w*x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74d5c6cf-4760-467b-a6f8-16673eec5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The special thing is here that when requires_grad is set to true\n",
    "#Then pytorch go and calculates the derivative of result easily.\n",
    "#y.backward() goes and searches for the elements it has been created which are x,w,b\n",
    "#And for the ones that with the requires_grad is true it calculates dy/dw, dy/db etc.\n",
    "#The partial derivatives\n",
    "#Backward seems logical since it goes back and takes the derivatives wrt to its predecessors\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8edfb50e-9c68-4953-b075-ff55c7516e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw is: tensor(3.)\n",
      "dy/dx is: None\n",
      "dy/db is: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#After this method is called then the derivative is recorded to the tensors.\n",
    "#x's gradient is none since we did not set requires_grad to True above\n",
    "print(\"dy/dw is: \" + str(w.grad))\n",
    "print(\"dy/dx is: \" + str(x.grad))\n",
    "print(\"dy/db is: \" + str(b.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ee5bd8e-e323-43fb-8484-6f3ecb92348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try backward()\n",
    "z = torch.tensor(12.,requires_grad = True)\n",
    "q = torch.tensor(3.,requires_grad = True)\n",
    "f = 2*z + 3*q\n",
    "k = 2*f + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2c7a067-7f0b-488d-a6dd-73a13acdb248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaa87c30-5754-4185-810c-7738179d1f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b83f2176-7653-4c86-bc9a-65989b71cef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c634b4c8-4e29-43d5-9399-374a49e301f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(70., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fc9aa4d-2470-41a7-8e35-7ba8d786b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bbe4459-c287-4547-8b15-34dd88f21dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/_tls9hb53pqg18gnfh6ghf5c0000gn/T/ipykernel_89751/2031286587.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  f.grad\n"
     ]
    }
   ],
   "source": [
    "#It does go to the prior steps\n",
    "#Why f not work ?\n",
    "f.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8657ee3-876c-4827-8ec0-0b9f8e136352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcf32c05-04b3-4993-98cf-817354826915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adc4a0-c93a-4e7c-8f80-f96be9b45e5b",
   "metadata": {},
   "source": [
    "# Interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97165a45-d451-46f5-b710-5987a28b70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Pytorch has direct support for numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7c370aa-e5ed-4299-8ab3-55bbe80462b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.array([[1,2.0],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27b778b0-0327-43bf-a1e6-056c141d65cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2653a0e3-9cbf-461d-a07e-eb141d5ef7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b43c7cc-c95e-4a3e-9879-b61c84601016",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_np = torch.from_numpy(np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0753f02-4cb4-4352-9cf3-d85dc41da44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "910d4501-b7ad-4fba-8b9c-9c792b2cdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dtypes are the same!\n",
    "#Also we can convert from tensors to numpy arrays as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53f8e80e-3590-4288-95bf-0d92442fe6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_from_tensor = t_np.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c2e853-731f-41b5-ae2b-acb01c6357f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6f9f25d-34ad-4e27-a0a5-0cd02734cecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393b1b7-be8d-40ac-9817-2e36e7cfb312",
   "metadata": {},
   "source": [
    "# Some Useful Attributes & Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65226b21-4da2-47a1-bc46-3c1a1bd5261e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4797, 0.3248, 0.2510],\n",
       "        [0.5877, 0.4688, 0.4364]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create random tensors from a uniform distribution\n",
    "rand_tensor = torch.rand((2,3))\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42401a54-8163-4fde-aafa-a9053873d533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar to Numpy one and 0 matrices\n",
    "ones_tensor = torch.ones((2,3))\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04e55de9-63b5-45cf-9637-2d275d020893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros((2,3))\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65e5a37f-7bda-4bcc-a09f-b790d5c0a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Very Numpy-Like\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b297c0d-6299-4ca7-8d89-110b68e4fd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0555, 1.4930],\n",
       "        [1.0555, 1.4930]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "\n",
    "#Matrix Multiplication\n",
    "y1 = ones_tensor @ rand_tensor.T\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d16f5d10-5b5f-45fd-a68a-220ffeb4df84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0555, 1.4930],\n",
       "        [1.0555, 1.4930]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix Multiplication\n",
    "y2 = ones_tensor.matmul(rand_tensor.T)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7f8bad0-9aa3-42c4-9d72-fc0c15ba8d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5493, 0.2210],\n",
       "        [0.6969, 0.6684]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = torch.rand_like(y1)\n",
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "388b5b5a-e5cf-4850-aaed-3a15a47e8837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0555, 1.4930],\n",
       "        [1.0555, 1.4930]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(ones_tensor, rand_tensor.T, out=y3)\n",
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c98bc9f-a25e-4eac-b1bf-6ff3a8c8ab37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26438d57-1f0a-459f-b65e-e6bc6f124d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "befbef22-0d5d-4e90-969f-921cedaf2961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cf7ed-6e6f-41a2-980a-ea9abf56247c",
   "metadata": {},
   "source": [
    "# Creating Linear Regression with Torch's Tensors and Gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a9236-2a38-4939-9fad-6ab72a20cffc",
   "metadata": {},
   "source": [
    "## Create Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc0fb7f8-8d21-48a5-82ff-ccba5df92a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First I will create Fake Data Using Numpy\n",
    "#Create normal random numbers - feature 1\n",
    "norm_rand = np.random.normal(loc=100.0,scale = 4.0,size = 1000).reshape(1000,1)\n",
    "#feature 2\n",
    "norm_rand_2 = np.random.normal(loc=12.0,scale = 10.0,size = 1000).reshape(1000,1)\n",
    "#Bind those together\n",
    "X = np.concatenate([norm_rand,norm_rand_2],axis=1)\n",
    "X = X.T\n",
    "W = np.array([12.0,-4.0]).reshape(2,1)\n",
    "b = np.array([-23.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c38a1ff-9326-49b0-9fdf-65bfe88c7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30def229-35b9-418b-b743-b79c533dd214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a19ef3d5-9264-49bb-9f5c-8a26fe631b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Linearly Created Data\n",
    "y = W.T @ X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04a4614c-ffc5-4c43-b983-6be2b86e8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce8f3309-41e0-421e-a630-605d8a6750de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Pandas Data Frame to make it more visual\n",
    "data = pd.DataFrame(X.T)\n",
    "data.columns = [\"Feature_1\",\"Feature_2\"]\n",
    "data[\"Target\"] = y.T\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82520019-6077-4238-9e6d-11ced45c60dc",
   "metadata": {},
   "source": [
    "## Build The Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6362bb-a8a3-44ea-bf68-a267a96afae9",
   "metadata": {},
   "source": [
    "Since we created the data itself we know the w1,w2 and b but let us forget that, they will be used to compare our model's quality later.\n",
    "Say that in real life we had a data like this and want to create a regression model. Since it is created via numpy we dont need any preparation,cleaning etc. Only convert them to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59edde8e-87f3-4d9e-8a5a-eee8d5bf9f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.630166</td>\n",
       "      <td>20.503881</td>\n",
       "      <td>1102.546469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.499316</td>\n",
       "      <td>11.845502</td>\n",
       "      <td>1159.609782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.251646</td>\n",
       "      <td>1.638753</td>\n",
       "      <td>1065.464733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.158853</td>\n",
       "      <td>11.406419</td>\n",
       "      <td>1109.280562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.465894</td>\n",
       "      <td>9.791046</td>\n",
       "      <td>1191.426547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_1  Feature_2       Target\n",
       "0  100.630166  20.503881  1102.546469\n",
       "1  102.499316  11.845502  1159.609782\n",
       "2   91.251646   1.638753  1065.464733\n",
       "3   98.158853  11.406419  1109.280562\n",
       "4  104.465894   9.791046  1191.426547"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68d9978d-21cf-4cd5-93e1-f6cf3792e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_t = torch.from_numpy(np.array(data[[\"Feature_1\",\"Feature_2\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8c40181-7a20-41a0-bd4a-7266d41019e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42a8a2ae-f64f-45b3-bbb4-d9b8270230b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9450943-ef77-4254-bc1c-34ff40fd3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_t = torch.from_numpy(np.array(data[[\"Target\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "106b1319-ffc1-499c-aa73-616f8c2d1b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eff97bbb-bc8c-4e2c-b245-4166682b24b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5bd4a455-ccf1-4bf5-bf26-b334842e9d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.6302,  20.5039],\n",
       "        [102.4993,  11.8455],\n",
       "        [ 91.2516,   1.6388],\n",
       "        ...,\n",
       "        [ 99.4448,  16.7060],\n",
       "        [105.9178,   0.9631],\n",
       "        [100.0590,   9.7229]], dtype=torch.float64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6986a-d001-4dfe-bd9f-a09c0c2ae217",
   "metadata": {},
   "source": [
    "### Linear Regression Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0441f02-6fcc-4eca-b93f-7fd55ef291ee",
   "metadata": {},
   "source": [
    "First we will need a function to execute linear regression given weigths and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8770e-69f9-4b09-b199-2bee915d745a",
   "metadata": {},
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a6e467e0-6a7d-4ca9-a553-0574c3d101c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes data, weights and bias\n",
    "#For simplicity it does not check dimensions we will provide it in the right directions\n",
    "def lin_reg (X_,w_,b_):\n",
    "    #Check shapes\n",
    "    result = X_ @ w_\n",
    "    result = result + b_\n",
    "\n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ab669e76-5b61-4410-b9ba-abf13a84b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us Define random weigths and bias\n",
    "rand_w = torch.randn(2,1,requires_grad=True,dtype = torch.float64)\n",
    "rand_b = torch.randn(1,requires_grad=True,dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "70e2191a-00a9-4f83-9ea5-49e2ef422bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-22.045330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-37.522691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48.018274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-35.752294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-42.072639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0 -22.045330\n",
       "1 -37.522691\n",
       "2 -48.018274\n",
       "3 -35.752294\n",
       "4 -42.072639"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For random weights and biases it calculates a linear regression approximation\n",
    "pd.DataFrame(lin_reg(Input_t,rand_w,rand_b).detach().numpy()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "31962eb5-611c-49a0-895d-556003869ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = lin_reg(Input_t,rand_w,rand_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be2a3584-5fd6-4582-a852-4163bf4080bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1102.546469\n",
       "1    1159.609782\n",
       "2    1065.464733\n",
       "3    1109.280562\n",
       "4    1191.426547\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Target\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e733b-9fbf-4714-8611-0b29fdb9864c",
   "metadata": {},
   "source": [
    "#### Loss Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564d3bf-8e5b-432a-9a1f-d03f319005fa",
   "metadata": {},
   "source": [
    "As the loss function, I will use least squares methodology. Thus we will try to minimize mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0792673c-b7d7-44a8-8d53-ab2f7020b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(preds,reals):\n",
    "    squared_loss = (preds-reals)**2\n",
    "    mean_sq_loss = torch.sum(squared_loss)/ squared_loss.numel()\n",
    "    return mean_sq_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76adc581-40d1-4b36-88b4-8025b7036ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1205818.4543, dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss(lin_reg(Input_t,rand_w,rand_b),Target_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7a44d-4877-4ce2-9119-499a08c17251",
   "metadata": {},
   "source": [
    "#### Compute Gradients & Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210e544-fb48-4e31-bc52-dcce754b53eb",
   "metadata": {},
   "source": [
    "Now since we have the model and the loss we will need to find the correct weights and bias by taking the gradient of the loss\n",
    "w.r.t weights and bias. That way we will set the weights and bias in such as way that we will decrease the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caea171-3933-4967-b263-3de9b81966a5",
   "metadata": {},
   "source": [
    "Since loss is  a function of the linear model and target data.\n",
    "And linear model is a function of weights & bias.The input features and the target is the data. So the changing part of the model are weights and bias. Thus we try to set them so that the error decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3fe29489-e657-4db5-854c-71ac09d8c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_loss(lin_reg(Input_t,rand_w,rand_b),Target_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a109691e-e628-49b0-9388-9fddc544dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calculates the derivative of the Loss w.r.t. to the tensors that has the requires_grad = True\n",
    "#We set those true for w and b\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "10b31c4a-cdf5-4d68-9dcc-23676c508e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivates of W and b w.r.t to the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2eeb64fc-72eb-451f-95b3-8ab058b1d6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-219590.7200],\n",
       "        [ -25671.3118]], dtype=torch.float64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c5784394-9e90-4ab0-a214-2710e1005ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2193.5898], dtype=torch.float64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3fee6770-d339-492b-8061-d3fc58605648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A small but important detail is that pytorch accumulates the derivatives.\n",
    "#So we need to make them 0 before calculating the gradient for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5c6db065-00f3-4841-a9ed-50e9a34d58d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_w.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "947dc3a0-1cac-42f0-9432-1a19ccd64218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b7aecbc3-b880-44e1-b1f4-f4d0c860829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9661a9b2-77bd-406a-8bc7-ffb66524bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can define the Gradient Descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "01fbc384-66eb-4b0a-bf71-a9fb436a500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad_Desc(X_,w_,b_,Y_,iter =10,alpha=0.00001):\n",
    "\n",
    "    #w_init = w_\n",
    "    #b_init = b_\n",
    "\n",
    "    i = 0\n",
    "    while i<iter:\n",
    "        print(i)\n",
    "        #Calculate the current predictions with current w_,b_\n",
    "        current_preds = lin_reg(X_,w_,b_)\n",
    "        #print(\"Current predictions are : \" +  str(current_preds))\n",
    "        current_preds.retain_grad()\n",
    "        #Calculate the loss with current w_,b_\n",
    "        current_loss = model_loss(current_preds,Y_)\n",
    "        print(\"Current loss is : \" +  str(current_loss))\n",
    "        #Now Calculate the gradients\n",
    "        current_loss.backward()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            w_ = w_ - alpha*w_.grad\n",
    "            b_ = b_ - alpha*b_.grad\n",
    "\n",
    "\n",
    "            #Reset the gradients\n",
    "            #w_.grad.zero_()\n",
    "            #b_.grad.zero_()\n",
    "        i+=1\n",
    "\n",
    "\n",
    "    return w_,b_\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "679ecd1d-da70-4591-af4c-3f068717fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Current loss is : tensor(1361263.7246, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "can't retain_grad on Tensor that has requires_grad=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[318], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mGrad_Desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInput_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrand_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrand_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTarget_t\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[316], line 12\u001b[0m, in \u001b[0;36mGrad_Desc\u001b[0;34m(X_, w_, b_, Y_, iter, alpha)\u001b[0m\n\u001b[1;32m     10\u001b[0m current_preds \u001b[38;5;241m=\u001b[39m lin_reg(X_,w_,b_)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(\"Current predictions are : \" +  str(current_preds))\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mcurrent_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretain_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Calculate the loss with current w_,b_\u001b[39;00m\n\u001b[1;32m     14\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m model_loss(current_preds,Y_)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: can't retain_grad on Tensor that has requires_grad=False"
     ]
    }
   ],
   "source": [
    "Grad_Desc(Input_t,rand_w,rand_b,Target_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11192d-f85d-4914-84c4-54f4a8e5e853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276360c-8f64-4a49-9c59-166a691fa003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
